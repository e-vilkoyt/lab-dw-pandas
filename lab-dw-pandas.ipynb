{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045146f-f4f7-44d9-8cd9-130d6400c73a",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Customer - Customer ID\n",
    "\n",
    "- ST - State where customers live\n",
    "\n",
    "- Gender - Gender of the customer\n",
    "\n",
    "- Education - Background education of customers \n",
    "\n",
    "- Customer Lifetime Value - Customer lifetime value(CLV) is the total revenue the client will derive from their entire relationship with a customer. In other words, is the predicted or calculated value of a customer over their entire duration as a policyholder with the insurance company. It is an estimation of the net profit that the insurance company expects to generate from a customer throughout their relationship with the company. Customer Lifetime Value takes into account factors such as the duration of the customer's policy, premium payments, claim history, renewal likelihood, and potential additional services or products the customer may purchase. It helps insurers assess the long-term profitability and value associated with retaining a particular customer.\n",
    "\n",
    "- Income - Customers income\n",
    "\n",
    "- Monthly Premium Auto - Amount of money the customer pays on a monthly basis as a premium for their auto insurance coverage. It represents the recurring cost that the insured person must pay to maintain their insurance policy and receive coverage for potential damages, accidents, or other covered events related to their vehicle.\n",
    "\n",
    "- Number of Open Complaints - Number of complaints the customer opened\n",
    "\n",
    "- Policy Type - There are three type of policies in car insurance (Corporate Auto, Personal Auto, and Special Auto)\n",
    "\n",
    "- Vehicle Class - Type of vehicle classes that customers have Two-Door Car, Four-Door Car SUV, Luxury SUV, Sports Car, and Luxury Car\n",
    "\n",
    "- Total Claim Amount - the sum of all claims made by the customer. It represents the total monetary value of all approved claims for incidents such as accidents, theft, vandalism, or other covered events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72419b-20fc-4905-817a-8c83abc59de6",
   "metadata": {},
   "source": [
    "External Resources: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91437bd5-59a6-49c0-8150-ef0e6e6eb253",
   "metadata": {},
   "source": [
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types.\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics.\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc26113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns:\n",
      "['Customer', 'ST', 'GENDER', 'Education', 'Policy Type', 'Vehicle Class']\n",
      "\n",
      "Data in categorical columns:\n",
      "\n",
      "Data in Customer:\n",
      "0    RB50392\n",
      "1    QZ44356\n",
      "2    AI49188\n",
      "3    WW63253\n",
      "4    GA49547\n",
      "Name: Customer, dtype: category\n",
      "Categories (1071, object): ['AA71604', 'AB13432', 'AB60627', 'AB72731', ..., 'ZX64745', 'ZX86243', 'ZZ91716', 'ZZ97035']\n",
      "\n",
      "Data in ST:\n",
      "0    Washington\n",
      "1       Arizona\n",
      "2        Nevada\n",
      "3    California\n",
      "4    Washington\n",
      "Name: ST, dtype: category\n",
      "Categories (8, object): ['AZ', 'Arizona', 'Cali', 'California', 'Nevada', 'Oregon', 'WA', 'Washington']\n",
      "\n",
      "Data in GENDER:\n",
      "0    NaN\n",
      "1      F\n",
      "2      F\n",
      "3      M\n",
      "4      M\n",
      "Name: GENDER, dtype: category\n",
      "Categories (5, object): ['F', 'Femal', 'M', 'Male', 'female']\n",
      "\n",
      "Data in Education:\n",
      "0                  Master\n",
      "1                Bachelor\n",
      "2                Bachelor\n",
      "3                Bachelor\n",
      "4    High School or Below\n",
      "Name: Education, dtype: category\n",
      "Categories (6, object): ['Bachelor', 'Bachelors', 'College', 'Doctor', 'High School or Below', 'Master']\n",
      "\n",
      "Data in Policy Type:\n",
      "0     Personal Auto\n",
      "1     Personal Auto\n",
      "2     Personal Auto\n",
      "3    Corporate Auto\n",
      "4     Personal Auto\n",
      "Name: Policy Type, dtype: category\n",
      "Categories (3, object): ['Corporate Auto', 'Personal Auto', 'Special Auto']\n",
      "\n",
      "Data in Vehicle Class:\n",
      "0    Four-Door Car\n",
      "1    Four-Door Car\n",
      "2     Two-Door Car\n",
      "3              SUV\n",
      "4    Four-Door Car\n",
      "Name: Vehicle Class, dtype: category\n",
      "Categories (6, object): ['Four-Door Car', 'Luxury Car', 'Luxury SUV', 'SUV', 'Sports Car', 'Two-Door Car']\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "                            count          mean           std        min  \\\n",
      "Customer Lifetime Value       0.0           NaN           NaN        NaN   \n",
      "Income                     1071.0  39295.701214  30469.427060   0.000000   \n",
      "Monthly Premium Auto       1071.0    193.234360   1601.190369  61.000000   \n",
      "Number of Open Complaints  1071.0      1.000000      0.000000   1.000000   \n",
      "Total Claim Amount         1071.0    404.986909    293.027260   0.382107   \n",
      "\n",
      "                                    25%           50%      75%           max  \n",
      "Customer Lifetime Value             NaN           NaN      NaN           NaN  \n",
      "Income                     14072.000000  36234.000000  64631.0  99960.000000  \n",
      "Monthly Premium Auto          68.000000     83.000000    109.5  35354.000000  \n",
      "Number of Open Complaints      1.000000      1.000000      1.0      1.000000  \n",
      "Total Claim Amount           202.157702    354.729129    532.8   2893.239678  \n",
      "\n",
      "Median values for numerical columns:\n",
      "Customer Lifetime Value               NaN\n",
      "Income                       36234.000000\n",
      "Monthly Premium Auto            83.000000\n",
      "Number of Open Complaints        1.000000\n",
      "Total Claim Amount             354.729129\n",
      "dtype: float64\n",
      "\n",
      "Mode values for numerical columns:\n",
      "Customer Lifetime Value        NaN\n",
      "Income                         0.0\n",
      "Monthly Premium Auto          65.0\n",
      "Number of Open Complaints      1.0\n",
      "Total Claim Amount           321.6\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Summary statistics for categorical columns:\n",
      "              count unique            top freq\n",
      "Customer       1071   1071        AA71604    1\n",
      "ST             1071      8         Oregon  320\n",
      "GENDER          954      5              F  457\n",
      "Education      1071      6       Bachelor  324\n",
      "Policy Type    1071      3  Personal Auto  780\n",
      "Vehicle Class  1071      6  Four-Door Car  576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Cargar el dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Paso 2: Convertir columnas num√©ricas\n",
    "data['Customer Lifetime Value'] = data['Customer Lifetime Value'].astype(str).str.replace(r'[\\$,]', '', regex=True)\n",
    "data['Customer Lifetime Value'] = pd.to_numeric(data['Customer Lifetime Value'], errors='coerce')\n",
    "\n",
    "data['Number of Open Complaints'] = data['Number of Open Complaints'].astype(str).str.extract(r'(\\d+)')[0]\n",
    "data['Number of Open Complaints'] = pd.to_numeric(data['Number of Open Complaints'], errors='coerce')\n",
    "\n",
    "# Convertir columnas categ√≥ricas\n",
    "categorical_columns = ['Customer', 'ST', 'GENDER', 'Education', 'Policy Type', 'Vehicle Class']\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# Verificar columnas categ√≥ricas\n",
    "categorical_columns = [col for col in categorical_columns if col in data.columns and data[col].dtype.name == 'category']\n",
    "\n",
    "print(\"\\nCategorical columns:\")\n",
    "print(categorical_columns)\n",
    "\n",
    "# Verificar datos en las columnas categ√≥ricas\n",
    "print(\"\\nData in categorical columns:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nData in {col}:\")\n",
    "    print(data[col].head())\n",
    "\n",
    "# Paso 3: Estad√≠sticas descriptivas\n",
    "numerical_columns = data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Calcular estad√≠sticas para columnas num√©ricas\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "summary_stats = data[numerical_columns].describe().T\n",
    "print(summary_stats)\n",
    "\n",
    "# Calcular mediana y moda para columnas num√©ricas\n",
    "median_values = data[numerical_columns].median()\n",
    "mode_values = data[numerical_columns].mode().iloc[0]\n",
    "\n",
    "print(\"\\nMedian values for numerical columns:\")\n",
    "print(median_values)\n",
    "\n",
    "print(\"\\nMode values for numerical columns:\")\n",
    "print(mode_values)\n",
    "\n",
    "# Verificar y describir columnas categ√≥ricas\n",
    "if categorical_columns:\n",
    "    print(\"\\nSummary statistics for categorical columns:\")\n",
    "    categorical_summary = data[categorical_columns].describe(include='category').T\n",
    "    print(categorical_summary)\n",
    "else:\n",
    "    print(\"No categorical columns available for description.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a703890-63db-4944-b7ab-95a4f8185120",
   "metadata": {},
   "source": [
    "## Challenge 2: analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb0c4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 less common customer locations (states):\n",
      "ST\n",
      "AZ             25\n",
      "WA             30\n",
      "Washington     81\n",
      "Nevada         98\n",
      "Cali          120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Verificar si la columna 'ST' existe en el conjunto de datos\n",
    "if 'ST' in data.columns:\n",
    "    # Paso 1: Crear una Serie con las frecuencias de ubicaciones (estados en este caso)\n",
    "    location_counts = data['ST'].value_counts()\n",
    "\n",
    "    # Paso 2: Obtener las 5 ubicaciones menos comunes en orden ascendente\n",
    "    less_common_locations = location_counts.nsmallest(5)\n",
    "\n",
    "    print(\"\\nTop 5 less common customer locations (states):\")\n",
    "    print(less_common_locations)\n",
    "else:\n",
    "    print(\"The column 'ST' does not exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80f43-4afa-43c7-a78a-c917444da4e0",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13997-1555-4f98-aca6-970fda1d2c3f",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da11a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of policies sold for each type of policy:\n",
      "Policy Type\n",
      "Personal Auto     780\n",
      "Corporate Auto    234\n",
      "Special Auto       57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Policy type with the highest number of policies sold:\n",
      "Personal Auto with 780 policies sold.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Verificar si la columna 'Policy Type' existe en el conjunto de datos\n",
    "if 'Policy Type' in data.columns:\n",
    "    # Paso 1: Contar el n√∫mero de pol√≠ticas vendidas por tipo de p√≥liza\n",
    "    policy_counts = data['Policy Type'].value_counts()\n",
    "\n",
    "    # Paso 2: Encontrar el tipo de p√≥liza con el mayor n√∫mero de ventas\n",
    "    most_common_policy_type = policy_counts.idxmax()\n",
    "    most_common_policy_count = policy_counts.max()\n",
    "\n",
    "    print(\"\\nTotal number of policies sold for each type of policy:\")\n",
    "    print(policy_counts)\n",
    "\n",
    "    print(f\"\\nPolicy type with the highest number of policies sold:\")\n",
    "    print(f\"{most_common_policy_type} with {most_common_policy_count} policies sold.\")\n",
    "else:\n",
    "    print(\"The column 'Policy Type' does not exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b863fd3-bf91-4d5d-86eb-be29ed9f5b70",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a lower income than those with Corporate Auto. How does the average income compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386d75-2810-4aa1-93e0-9485aa12d552",
   "metadata": {},
   "source": [
    "- Use *loc* to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average income for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3243095b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average income for each policy type:\n",
      "Personal Auto: $38180.70\n",
      "Corporate Auto: $41390.31\n",
      "\n",
      "Customers with Personal Auto have a lower average income than those with Corporate Auto.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Convertir 'Income' a num√©rico en caso de que no lo sea\n",
    "data['Income'] = pd.to_numeric(data['Income'], errors='coerce')\n",
    "\n",
    "# Verificar si la columna 'Policy Type' y 'Income' existen en el dataset\n",
    "if 'Policy Type' in data.columns and 'Income' in data.columns:\n",
    "    # Paso 1: Crear DataFrames para cada tipo de p√≥liza\n",
    "    personal_auto_df = data.loc[data['Policy Type'] == 'Personal Auto']\n",
    "    corporate_auto_df = data.loc[data['Policy Type'] == 'Corporate Auto']\n",
    "\n",
    "    # Paso 2: Calcular el ingreso promedio para cada tipo de p√≥liza\n",
    "    average_income_personal_auto = personal_auto_df['Income'].mean()\n",
    "    average_income_corporate_auto = corporate_auto_df['Income'].mean()\n",
    "\n",
    "    # Paso 3: Imprimir los resultados\n",
    "    print(\"\\nAverage income for each policy type:\")\n",
    "    print(f\"Personal Auto: ${average_income_personal_auto:.2f}\")\n",
    "    print(f\"Corporate Auto: ${average_income_corporate_auto:.2f}\")\n",
    "\n",
    "    # Comparar los ingresos\n",
    "    if average_income_personal_auto < average_income_corporate_auto:\n",
    "        print(\"\\nCustomers with Personal Auto have a lower average income than those with Corporate Auto.\")\n",
    "    else:\n",
    "        print(\"\\nCustomers with Corporate Auto have a lower average income than those with Personal Auto.\")\n",
    "else:\n",
    "    print(\"The columns 'Policy Type' or 'Income' do not exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b16c27-f4a5-4727-a229-1f88671cf4e2",
   "metadata": {},
   "source": [
    "### Bonus: Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac584986-299b-475f-ac2e-928c16c3f512",
   "metadata": {},
   "source": [
    "Your goal is to identify customers with a high policy claim amount.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3af5f1-6023-4b05-9c01-d05392daa650",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d234634-50bd-41e0-88f7-d5ba684455d1",
   "metadata": {},
   "source": [
    "*Hint 2: check `Boolean selection according to the values of a single column` in https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81356300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for 'Total Claim Amount':\n",
      "count    1071.000000\n",
      "mean      404.986909\n",
      "std       293.027260\n",
      "min         0.382107\n",
      "25%       202.157702\n",
      "50%       354.729129\n",
      "75%       532.800000\n",
      "max      2893.239678\n",
      "Name: Total Claim Amount, dtype: float64\n",
      "\n",
      "75th percentile (threshold) for 'Total Claim Amount': $532.80\n",
      "\n",
      "Summary statistics for high policy claim amounts:\n",
      "                      count          mean           std    min         25%  \\\n",
      "Income                264.0  23677.344697  27013.483721    0.0    0.000000   \n",
      "Monthly Premium Auto  264.0    165.193182    623.930992   63.0   99.000000   \n",
      "Total Claim Amount    264.0    782.228263    292.751640  537.6  606.521741   \n",
      "\n",
      "                               50%       75%           max  \n",
      "Income                18807.000000  42423.75  99316.000000  \n",
      "Monthly Premium Auto    114.000000    133.25  10202.000000  \n",
      "Total Claim Amount      679.597985    851.40   2893.239678  \n",
      "\n",
      "Number of customers with high policy claim amounts: 264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Convertir 'Total Claim Amount' a num√©rico en caso de que no lo sea\n",
    "data['Total Claim Amount'] = pd.to_numeric(data['Total Claim Amount'], errors='coerce')\n",
    "\n",
    "# Paso 1: Revisar estad√≠sticas descriptivas para 'Total Claim Amount'\n",
    "print(\"\\nSummary statistics for 'Total Claim Amount':\")\n",
    "print(data['Total Claim Amount'].describe())\n",
    "\n",
    "# Paso 2: Determinar el umbral del 75¬∫ percentil\n",
    "percentile_75 = data['Total Claim Amount'].quantile(0.75)\n",
    "print(f\"\\n75th percentile (threshold) for 'Total Claim Amount': ${percentile_75:.2f}\")\n",
    "\n",
    "# Paso 3: Crear un DataFrame con los clientes cuyo monto de reclamo es mayor que el umbral del 75¬∫ percentil\n",
    "high_claims_df = data[data['Total Claim Amount'] > percentile_75]\n",
    "\n",
    "# Paso 4: Calcular estad√≠sticas descriptivas para el DataFrame de altos reclamos\n",
    "print(\"\\nSummary statistics for high policy claim amounts:\")\n",
    "high_claims_summary = high_claims_df.describe().T\n",
    "print(high_claims_summary)\n",
    "\n",
    "# Imprimir el n√∫mero de clientes con altos reclamos\n",
    "print(f\"\\nNumber of customers with high policy claim amounts: {high_claims_df.shape[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
